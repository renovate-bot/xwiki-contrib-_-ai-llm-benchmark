{"id": "dev:IRC.xwikiArchive20131113", "url": "https://dev.xwiki.org/xwiki/bin/view/IRC/xwikiArchive20131113", "title": "IRC Archive for channel #xwiki on 13 November 2013 - XWiki", "collection": "Eval-Large", "mimetype": "text/markdown", "language": "en", "content": "\n<abusenius>\u00a0has quit  \n00:00\u00a0<vmassol>\u00a0has quit  \n00:57\u00a0<vmassol>\u00a0has joined #xwiki  \n01:00\u00a0<jtafurth>\u00a0is now known as <jtafurth|away>  \n01:02\u00a0<vmassol>\u00a0has quit  \n01:05\u00a0<Denis>\u00a0has quit  \n01:23\u00a0<jtafurth|away>\u00a0is now known as <jtafurth>  \n01:38\u00a0<sdumitriu1>\u00a0has quit  \n01:57\u00a0<vmassol>\u00a0has joined #xwiki  \n02:01\u00a0<vmassol>\u00a0has quit  \n02:57\u00a0<vmassol>\u00a0has joined #xwiki  \n03:01\u00a0<vmassol>\u00a0has quit  \n03:05\u00a0<jtafurth>\u00a0is now known as <jtafurth|away>  \n03:57\u00a0<vmassol>\u00a0has joined #xwiki  \n04:01\u00a0<vmassol>\u00a0has quit  \n04:30\u00a0<Denis>\u00a0has joined #xwiki  \n04:57\u00a0<vmassol>\u00a0has joined #xwiki  \n05:01\u00a0<vmassol>\u00a0has quit  \n05:57\u00a0<vmassol>\u00a0has joined #xwiki  \n06:00\u00a0<Denis1>\u00a0has joined #xwiki  \n06:01\u00a0<vmassol>\u00a0has quit  \n06:02\u00a0<Denis>\u00a0has quit  \n06:04\u00a0<Denis1>\u00a0has quit  \n06:57\u00a0<vmassol>\u00a0has joined #xwiki  \n07:02\u00a0<vmassol>\u00a0has quit  \n07:18\u00a0<vmassol>\u00a0has joined #xwiki  \n07:20\u00a0<vmassol1>\u00a0has joined #xwiki  \n07:20\u00a0<vmassol>\u00a0has quit  \n07:22\u00a0<vmassol1>\u00a0has quit  \n07:23\u00a0<vmassol>\u00a0has joined #xwiki  \n07:38\u00a0<mflorea>\u00a0has joined #xwiki  \n08:01\u00a0<Denis>\u00a0has joined #xwiki  \n08:06\u00a0<Denis>\u00a0has quit  \n08:36\u00a0<Denis>\u00a0has joined #xwiki  \n08:49\u00a0<tmortagne>\u00a0has joined #xwiki  \n08:58\u00a0<msmeria>\u00a0has joined #xwiki  \n09:21\u00a0<sburjan>\u00a0has joined #xwiki  \n09:25\u00a0<KermitTheFragger>\u00a0has joined #xwiki  \n09:38\u00a0<cjd>\u00a0has joined #xwiki  \n09:49\u00a0<evalica>\u00a0has joined #xwiki  \n10:04\u00a0<tmortagne>\u00a0has quit  \n10:09\u00a0<gdelhumeau>\u00a0has joined #xwiki  \n10:27\u00a0<msmeria>\u00a0hello, devs !  \n10:28\u00a0<Denis>\u00a0has quit  \n10:28\u00a0<msmeria>\u00a0I get this stack when shutting down the latest 5.3-snap: http://pastebin.com/H8wm9g6D  \n10:29\u00a0<Denis>\u00a0has joined #xwiki  \n10:31\u00a0<cjd>\u00a0Caused by: org.hibernate.exception.GenericJDBCException: Cannot open connection  \n10:31\u00a0<cjd>\u00a0it's a silly question but is the database possibly being stopped before the wiki?  \n10:33\u00a0<vmassol>\u00a0AFAIK we have a jira issue for this when shutting down  \n10:33\u00a0<cjd>\u00a0ahh  \n10:33\u00a0<vmassol>\u00a0http://jira.xwiki.org/browse/XWIKI-9597  \n10:35\u00a0<cjd>\u00a0we ought to just rewrite XWHS with raw jdbc instead of all this hibernate structure which isn't really used to anywhere near it's full potential  \n10:35\u00a0<vmassol>\u00a0no  \n10:36\u00a0<vmassol>\u00a0we should rewrite everything in C  \n10:36\u00a0<cjd>\u00a0it would be nice but then we would have to have only experts working on the core or else segfault :)  \n10:36\u00a0<vmassol>\u00a0or possibly ASM for even greater direct access to the machine  \n10:36\u00a0<vmassol>\u00a0no fwk!  \n10:37\u00a0<cjd>\u00a0ahh but with C you have \u00a0\u00a0\u00a0\u00a0asm volatile(.....)  \n10:37\u00a0<cjd>\u00a0or maybe writing that wrong  \n10:38\u00a0<gdelhumeau>\u00a0You may write our proper database too :)  \n10:38\u00a0<cjd>\u00a0databases are hard  \n10:38\u00a0<cjd>\u00a0it's easier to write commit();  \n10:39\u00a0<evalica>\u00a0hi - if I get \"java.lang.OutOfMemoryError: Java heap space\" on design.xwiki.org because of trying to import xar files bigger that 30MB, what is the solution? Increase the heap? I could do some manually stuff (delete attachments and re-add them) but not sure this is the right way  \n10:41\u00a0<cjd>\u00a0hmm I should write a one-page-at-a-time xar importer since it would actually only take me a few hours  \n10:41\u00a0<cjd>\u00a0I think there's a groovy script somewhere for very large imports  \n10:42\u00a0<cjd>\u00a0deleting and re-adding attachments would be a workable approach  \n10:42\u00a0<evalica>\u00a0I already imported all of the pages. I got 3 pages that didn't made the import because of the heap  \n10:42\u00a0<cjd>\u00a0ahh  \n10:42\u00a0<cjd>\u00a0I'd remove and manually add the attachments  \n10:43\u00a0<cjd>\u00a0there are \"nice\" solutions and there are ones which are complete by lunch  \n10:43\u00a0<evalica>\u00a0:) k let me - thanks  \n10:43\u00a0<vmassol>\u00a0why would removing attachment solve the issue?  \n10:43\u00a0<vmassol>\u00a0they're still in the history  \n10:43\u00a0<vmassol>\u00a0no?  \n10:44\u00a0<evalica>\u00a0well I import the page without history - since is minimizes the size  \n10:44\u00a0<vmassol>\u00a0that's not very good....  \n10:44\u00a0<vmassol>\u00a0we're loosing information  \n10:45\u00a0<vmassol>\u00a0loosing creator, who participated, etc  \n10:45\u00a0<evalica>\u00a0vincent - k - I understand - so what should I do?  \n10:45\u00a0<cjd>\u00a0\\*losing  \n10:45\u00a0<evalica>\u00a0http://incubator.myxwiki.org/xwiki/bin/view/Improvements/Skin4x  \n10:46\u00a0<evalica>\u00a0if I mannualy delete the attachemtns and re-add them - there are 76 attachments on it  \n10:46\u00a0<cjd>\u00a0hrm  \n10:46\u00a0<vmassol>\u00a0evalica: why don't you use large imports/large exports?  \n10:47\u00a0<evalica>\u00a0well yesterday I've use a script made by Edy that was importing them by REST - but this pages failed because of the heap  \n10:47\u00a0<vmassol>\u00a0but why oh why?  \n10:47\u00a0<vmassol>\u00a0why write yet another script that's not tested?  \n10:47\u00a0<vmassol>\u00a0when we have an app for large import/export  \n10:48\u00a0<vmassol>\u00a0and we've been using that approach for yeras  \n10:48\u00a0<vmassol>\u00a0years  \n10:48\u00a0<evalica>\u00a0are you reffering to the Admin tools?  \n10:48\u00a0<evalica>\u00a0because I tried them and they failed too  \n10:48\u00a0<vmassol>\u00a0I'm refering to the large import/export  \n10:49\u00a0<evalica>\u00a0http://extensions.xwiki.org/xwiki/bin/view/Extension/Admin+Tools+Application  \n10:50\u00a0<gdelhumeau>\u00a0http://extensions.xwiki.org/xwiki/bin/view/Extension/Large+XAR+Import  \n10:52\u00a0<tmortagne>\u00a0has joined #xwiki  \n10:54\u00a0<evalica>\u00a0so Admin.LargeExportBySpace export just by space and it failed yesterday because of the large number of pages. Also it writes on the file system so this means I need 2 admins to handle the move: one for myxwiki and the other for xwiki.org  \n10:54\u00a0<gdelhumeau>\u00a0Yes, the large XAR import is not so user friendly :(  \n10:55\u00a0<gdelhumeau>\u00a0It is designed for people who have admin right on the machine  \n10:55\u00a0<evalica>\u00a0anyway \u2026 I have just 3 more pages :|  \n11:01\u00a0<tmortagne>\u00a0use the one that really deserve having \"large\" in its name: http://extensions.xwiki.org/xwiki/bin/view/Extension/Large+XAR+Import ;)  \n11:05\u00a0<tmortagne>\u00a0http://extensions.xwiki.org/xwiki/bin/view/Extension/Large+Wiki+Export  \n11:06\u00a0<evalica>\u00a0so the conclusion is that I need access to the file system ?  \n11:07\u00a0<tmortagne>\u00a0evalica: there is wikistream in 5.2.1 if we are talking about xwiki.org so we could simply make it the default implementation of export action and you can use the standard export  \n11:07\u00a0<tmortagne>\u00a0it's just about putting xwiki.action.export.xar.usewikistream=1 in xwiki.cfg  \n11:08\u00a0<tmortagne>\u00a0no need for fs access in this case  \n11:08\u00a0<tmortagne>\u00a0(xwiki.action.export.xar.usewikistream=1 is the default in 5.3)  \n11:09\u00a0<cjd>\u00a0Do you have any advice for how to approach writing a wikistream serializer?  \n11:10\u00a0<tmortagne>\u00a0cjd: extend org.xwiki.wikistream.internal.AbstractBeanWikiStreamFactory  \n11:10\u00a0<tmortagne>\u00a0best right now is probably to look at existing ones  \n11:10\u00a0<tmortagne>\u00a0the \"simpler\" one is probably the XAR one  \n11:10\u00a0<tmortagne>\u00a0in xwiki-platform-wikistream-stream-xar module  \n11:11\u00a0<tmortagne>\u00a0basically you should provide your own version of the first 3 classes in org.xwiki.wikistream.xar.internal.output  \n11:11\u00a0<cjd>\u00a0ok  \n11:12\u00a0<cjd>\u00a0I'm vaguely interested in the idea of pushing all document histories over to the filesystem  \n11:12\u00a0<cjd>\u00a0so the DB is only holding the current version  \n11:13\u00a0<tmortagne>\u00a0ok  \n11:13\u00a0<cjd>\u00a0[toy idea]  \n11:13\u00a0<cjd>\u00a0user@ubnta8:~/wrk/xwiki-trunks/xwiki-platform$ find ./xwiki-platform-core/ -name 'AbstractBeanWikiStreamFactory.java'  \n11:13\u00a0<cjd>\u00a0user@ubnta8:~/wrk/xwiki-trunks/xwiki-platform$  \n11:14\u00a0<tmortagne>\u00a0cjd: please tell me if you see anything in the API that does not cover your use case and should be more generic  \n11:14\u00a0<cjd>\u00a0hmm now would indeed be the best time to have another implementation  \n11:14\u00a0<cjd>\u00a0oops was on stable-5.1  \n11:15\u00a0<tmortagne>\u00a0I have two very different implementation right now, the XAR serializer and the instance output (basically the generic importer)  \n11:15\u00a0<cjd>\u00a0how did you do the versioning?  \n11:15\u00a0<cjd>\u00a0in the xar  \n11:16\u00a0<cjd>\u00a0that was a huge pain for me because jRCS wants strings  \n11:16\u00a0<tmortagne>\u00a0the XAR serializer is 1.1 (considering the old one being 1.0)  \n11:16\u00a0<tmortagne>\u00a0ha you mean in the API ?  \n11:16\u00a0<msmeria>\u00a0has quit  \n11:16\u00a0<cjd>\u00a0I mean the XAR impl  \n11:17\u00a0<msmeria>\u00a0has joined #xwiki  \n11:17\u00a0<tmortagne>\u00a0I added a new \"version\" attribute in the <xwikidoc> element  \n11:17\u00a0<tmortagne>\u00a0if there is none then it's 1.0  \n11:18\u00a0<cjd>\u00a0but does it still export RCS nodes inside of the <version> block?  \n11:18\u00a0<tmortagne>\u00a0yes  \n11:19\u00a0<tmortagne>\u00a0I export it as it is if it's provided in the event  \n11:19\u00a0<tmortagne>\u00a0i.e. I don't play with it right now  \n11:19\u00a0<cjd>\u00a0ahh ok  \n11:20\u00a0<tmortagne>\u00a0first priority was to cover old serializer user cases, later I guess the only way is to have an optional dependency on jrcs and use it if present  \n11:20\u00a0<tmortagne>\u00a0the instance input module put the jrcs version string in the event if enabled  \n11:20\u00a0<cjd>\u00a0so the wikistream exporter says \"here is the document history\" and it gives you a blob of RCS nodes  \n11:21\u00a0<tmortagne>\u00a0yes  \n11:21\u00a0<tmortagne>\u00a0it's not part of the generic wikistream API  \n11:22\u00a0<tmortagne>\u00a0it's a XWiki special event known by instance and xar modules  \n11:22\u00a0<cjd>\u00a0ok  \n11:23\u00a0<tmortagne>\u00a0in the input module you usually use a proxy which takes care of sending what the output support and ignore what it does not  \n11:29\u00a0<cjd>\u00a0public abstract class AbstractXMLOutputWikiStream<P extends XMLOuputProperties> \u00a0<-- typo?\n"}