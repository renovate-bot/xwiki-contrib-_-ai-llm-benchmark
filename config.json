{
  "evaluator": {
    "model": "AI.Models.GPT4o",
    "temperature": 0.3,
    "stream": false
  },
  "embedding_model": {
    "model": "AI.Models.all-minilm",
    "temperature": 0.3,
    "dimension": 768,
    "stream": false
  },
  "tasks": [
    {
      "task": "RAG-qa",
      "settings": {
        "model": "AI.Models.qa_GPT4o",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "RAG-qa",
      "settings": {
        "model": "AI.Models.qa_GPT4o-mini",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "RAG-qa",
      "settings": {
        "model": "AI.Models.qa_claude3_5_sonet",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "RAG-qa",
      "settings": {
        "model": "AI.Models.qa_mistral2_large",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "RAG-qa",
      "settings": {
        "model": "AI.Models.qa_llama3_1_402b",
        "temperature": 0.45,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "RAG-qa",
      "settings": {
        "model": "AI.Models.qa_llama3_1_8b_Q4",
        "temperature": 0.45,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "RAG-qa",
      "settings": {
        "model": "AI.Models.qa_mixtral-8x22b",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "RAG-qa",
      "settings": {
        "model": "AI.Models.qa_mistral-nemo_12b_Q4",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "RAG-qa",
      "settings": {
        "model": "AI.Models.qa_gemma2_9B_Q4",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "RAG-qa",
      "settings": {
        "model": "AI.Models.qa_phi3_mini-128k_4b_Q4",
        "temperature": 0,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "RAG-qa",
      "settings": {
        "model": "AI.Models.qa_phi3_medium-128k_14b_Q4",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "RAG-qa",
      "settings": {
        "model": "AI.Models.qa_command-r_35B_Q4",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "RAG-qa",
      "settings": {
        "model": "AI.Models.qa_qwen2_7b_Q4",
        "temperature": 0,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "summarization",
      "settings": {
        "model": "AI.Models.GPT4o",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "summarization",
      "settings": {
        "model": "AI.Models.GPT4o-mini",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "summarization",
      "settings": {
        "model": "AI.Models.claude3_5_sonet",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "summarization",
      "settings": {
        "model": "AI.Models.mistral2_large",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "summarization",
      "settings": {
        "model": "AI.Models.llama3_1_402b",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "summarization",
      "settings": {
        "model": "AI.Models.llama3_1_8b_Q4",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "summarization",
      "settings": {
        "model": "AI.Models.mixtral-8x22b",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "summarization",
      "settings": {
        "model": "AI.Models.mistral-nemo_12b_Q4",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "summarization",
      "settings": {
        "model": "AI.Models.gemma2_9B_Q4",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "summarization",
      "settings": {
        "model": "AI.Models.phi3_mini-128k_4b_Q4",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "summarization",
      "settings": {
        "model": "AI.Models.phi3_medium-128k_14b_Q4",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "summarization",
      "settings": {
        "model": "AI.Models.command-r_35B_Q4",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "summarization",
      "settings": {
        "model": "AI.Models.qwen2_7b_Q4",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "text_generation",
      "settings": {
        "model": "AI.Models.GPT4o",
        "temperature": 0.3,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "text_generation",
      "settings": {
        "model": "AI.Models.GPT4o-mini",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "text_generation",
      "settings": {
        "model": "AI.Models.claude3_5_sonet",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "text_generation",
      "settings": {
        "model": "AI.Models.mistral2_large",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "text_generation",
      "settings": {
        "model": "AI.Models.llama3_1_402b",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "text_generation",
      "settings": {
        "model": "AI.Models.llama3_1_8b_Q4",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "text_generation",
      "settings": {
        "model": "AI.Models.mixtral-8x22b",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": false
    },
    {
      "task": "text_generation",
      "settings": {
        "model": "AI.Models.mistral-nemo_12b_Q4",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "text_generation",
      "settings": {
        "model": "AI.Models.gemma2_9B_Q4",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "text_generation",
      "settings": {
        "model": "AI.Models.phi3_mini-128k_4b_Q4",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "text_generation",
      "settings": {
        "model": "AI.Models.phi3_medium-128k_14b_Q4",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "text_generation",
      "settings": {
        "model": "AI.Models.command-r_35B_Q4",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": true
    },
    {
      "task": "text_generation",
      "settings": {
        "model": "AI.Models.qwen2_7b_Q4",
        "temperature": 0.8,
        "stream": false
      },
      "power_measurement": true
    }
  ]
}